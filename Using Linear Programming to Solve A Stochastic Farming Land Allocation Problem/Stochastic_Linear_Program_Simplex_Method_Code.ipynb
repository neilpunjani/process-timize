{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCrNZpEq8anv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "#defining the simplex method, It can be used to solve any LP.\n",
        "#it takes 5 matrices: the basic variables, indeces of the basic matrices, non-basic variables, Indeces of non-basic varibales, Objectve function coefficients, Constraints coefficients\n",
        "#the constraints RHS values are not needed during the iterations, but were used for debugging.\n",
        "def Simplex_Method(XB,IB,XN,IN,c,A,b):\n",
        "  while True:\n",
        "\n",
        "    m,n = A.shape                                           #storing the shape of A, which indicates the number of constraints and number of variables (including slacks and artificial variables)\n",
        "\n",
        "    B = np.zeros((m, m))                                    #storing the current iteration B matrix based on the indeces of the basic variables, stacked column by column from matrix A\n",
        "    for i in range(m):\n",
        "      B[:, i] = A[:, int(IB[:,i]-1)]\n",
        "\n",
        "    cB = np.zeros((m, 1))                                   #storing the current iteration cB column based on the indeces of the basic variables, stacked row by row from matrix c\n",
        "    for i in range(m):\n",
        "      cB[i, :] = c[int(IB[:,i]-1), :]\n",
        "\n",
        "    pi = np.linalg.solve(B.T, cB)                           #computing pi values using linalg function which solves a set of linear equations instead of getting the inverse of the a matrix\n",
        "\n",
        "    N_loc = 0                                               #initializing the location of each non-basic variable we got through\n",
        "    for j in range(n-m):                                    #going through the non basic variables indeces\n",
        "      cN = float(c[int(IN[:,j]-1),:])                       #getting the c value for the current non-basic variable\n",
        "      NN = A[:, int(IN[:,j]-1)].reshape(m,1)                #getting the A matrix column associated with the current non-basic variable\n",
        "      r = cN - (pi.T)@NN                                    #Calculating the reduced cost for the non-basic variable\n",
        "      if r < 0:                                             #checking if r is negative\n",
        "        Vin_enters = int(IN[:,j])                           #storing the index of the current non-basic variable with the negative r as the chosed variable to enter\n",
        "        break                                               #since the indeces are sorted, no need to check for more negative r values. following bland's rule by taking the variable with the smallest index\n",
        "      else:N_loc +=1                                        #updating the location\n",
        "\n",
        "    if N_loc == (n-m):                                      #if all r were positive (aka we went over all the non basic variables without getting a negative r), we're optimal, stop iterating\n",
        "      break\n",
        "\n",
        "    d_1 = np.linalg.solve(B, -NN)                           #computing d values using linalg function\n",
        "    e = np.zeros(((n-m), 1))                                #getting the e vector as all 0, same number as the non-basic variables\n",
        "    e[N_loc, :] = 1                                         #assigning 1 to the location of the chosen non-basic variable to enter the basic set\n",
        "    d_2 = np.vstack((d_1, e))                               #stacking d and e together (for demonstration and debuging only, was not used in the code)\n",
        "\n",
        "    #initializing Alpha, instead of using a random value, so we can start comparing the alpha values and get the smallest one\n",
        "    alpha_index = 0\n",
        "    for d_trial in d_1:                                     #going through the values of d - basic\n",
        "      d_trial = float(d_trial)\n",
        "      if d_trial < 0:\n",
        "        alpha = (-1*(float(XB[alpha_index]))/d_trial)+1     #initializing alpha as the first value that we got + 1\n",
        "        break\n",
        "      alpha_index += 1\n",
        "\n",
        "    #checking boundedness and calculating alpha\n",
        "    d_loc = 0                                               #initializing the location variable\n",
        "    positive_d = 0                                          #initialising the number of positive d\n",
        "    for d in d_1:                                           #going throuhg the d values\n",
        "      d = float(d)\n",
        "      if d < 0:                                             #checking if d is negative\n",
        "        alpha_New = (-1*(float(XB[d_loc])))/d               #computing Alpha for each d value < 0\n",
        "        if alpha_New < alpha:                               #updating alpha to the new smaller alpha\n",
        "          alpha = alpha_New\n",
        "          Vin_exits = int(IB[:, d_loc])                     #storing the indix of the variable with the smallest alpha to be removed from the basic variable set\n",
        "          V_exits_loc = d_loc                               #storing the location of the leaving variable\n",
        "        d_loc += 1                                          #updating the location\n",
        "      else:\n",
        "        positive_d +=1                                      #updating the number of positive d\n",
        "        d_loc += 1                                          #updating the location\n",
        "\n",
        "    if positive_d == d_loc:                                 #checking if all d is positive (unbounded)\n",
        "      XB = 'LP Unbounded'\n",
        "      XN = 'LP Unbounded'\n",
        "      IB = 'LP Unbounded'\n",
        "      IN = 'LP Unbounded'\n",
        "      break\n",
        "\n",
        "    XB_new = XB + (alpha * d_1)                             #calculating the new XB\n",
        "    X_exits = XB_new[V_exits_loc]                           #storing the value of the variable that left (for demonstration and debuging only, was not used in the code since it's 0)\n",
        "\n",
        "    XN_new = XN + (alpha * e)                               #calculating the new XN\n",
        "    X_enters = float(XN_new[N_loc])                         #storing the value of the variable that entered\n",
        "\n",
        "    XB = XB_new\n",
        "    XB[V_exits_loc] = X_enters                              #replacing the value of the variable that left with the one that entered\n",
        "    IB[0,V_exits_loc] = Vin_enters                          #replacing the index of the variable that left with the one that entered\n",
        "    XB = XB[np.argsort(IB)].reshape(m,1)                    #sorting XB to get in order based on the indices in IB\n",
        "    IB = np.sort(IB)                                        #sorting IB to get in order\n",
        "\n",
        "    XN = XN_new\n",
        "    XN[N_loc] = 0                                           #replacing the value of the variable that entered with 0\n",
        "    IN[0,N_loc] = Vin_exits                                 #replacing the index of the variable that entered with the one that left\n",
        "    IN = np.sort(IN)                                        #sorting IN to get in order\n",
        "\n",
        "  return XB, IB, XN, IN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def BIG_M(A,b,c):\n",
        "  #defining the Big M method since our problem needs artificial variables to initial a BFS.\n",
        "  #it needs Objectve function coefficients, Constraints coefficients, and constraints RHS values.\n",
        "\n",
        "  m,n = A.shape                                             #storing the shape of A, which indicates the number of constraints and number of variables\n",
        "\n",
        "  cb_1 = np.ones((m, 1))*1000000                            #creating the objective function coefficient to the new artificial variables (BIG M), as much as we have constaints\n",
        "  cn_1 = c\n",
        "  c_1 = np.vstack((cn_1, cb_1))                             #stacking the original c with the BIG M\n",
        "  XB_1 = b                                                  #giving the artificial variables the value of b as an initial basic variables\n",
        "  XN_1 = np.zeros(((n), 1))                                 #giving the rest of the variables a value of 0 as the non-basic variables\n",
        "\n",
        "  IB_1 = np.zeros((1, m))\n",
        "  for i in range(m):\n",
        "    IB_1[:, i] = i+n+1                                      #storing the basic variables indeces, starting from the number of the last original variable and increasing as much as we have constaints\n",
        "\n",
        "  IN_1 = np.zeros((1, n))\n",
        "  for i in range(n):\n",
        "    IN_1[:, i] = i+1                                        #storing the non-basic variables indeces, as much as the original variables.\n",
        "\n",
        "  identity = np.eye(m)\n",
        "  A_1 = np.hstack((A, identity))                            #adding an identity matrix with the size of constraints as the A coeffecient of the artificial variables\n",
        "\n",
        "  XB, IB, XN, IN = Simplex_Method(XB_1,IB_1,XN_1,IN_1,c_1,A_1,b)          #calling the simplex method fucntion to  solve our LP\n",
        "\n",
        "  for IB_index in range(IB.size):\n",
        "    if int(IB[:,IB_index]) > n:\n",
        "      if XB[IB_index,0] == 0:\n",
        "        for IN_index in range(IN.size):\n",
        "          if int(IN[:,IN_index]) <= n:\n",
        "            IB[:,IB_index] = int(IN[:,IN_index])            #if we have an artificial variable with a 0 value in our basic variables, it shall be replaced with a non-basic variable\n",
        "            IN = np.delete(IN, IN_index, axis=1)\n",
        "            XN = np.delete(XN, IN_index, axis=0)\n",
        "            break\n",
        "      else:                                                 #if we have an artificial variable with a non 0 value then either infeasible or the BIG M was not big enough\n",
        "        XB = 'infeasible or need bigger M'\n",
        "        XN = 'infeasible or need bigger M'\n",
        "\n",
        "  for IN_index in range(IN.size-1, -1, -1):                 #removing the artificial variables and there indeces from IN and XN\n",
        "    if int(IN[:,IN_index]) > n:\n",
        "      IN = np.delete(IN, IN_index, axis=1)\n",
        "      XN = np.delete(XN, IN_index, axis=0)\n",
        "\n",
        "  return XB,IB,XN,IN"
      ],
      "metadata": {
        "id": "FoGcwbhR8g-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Simplex_generated_data = pd.DataFrame(columns=['Scenarios_no', 'Objective_function_value', 'Time_needed', 'Largest_percentage_change'])\n",
        "\n",
        "for i_s in range(1, 602, 4):\n",
        "\n",
        "  number_of_scenarios = i_s                                      #deciding the number of variables\n",
        "  percentage = 0.0036                                            #deciding the percentage increment\n",
        "  probabilities = 1/number_of_scenarios\n",
        "\n",
        "  scenarios_list = np.array([])\n",
        "  for scene in range(number_of_scenarios):\n",
        "    scenarios_list = np.append(scenarios_list, scene+1)\n",
        "  percentage_list = ((scenarios_list - np.median(scenarios_list))*percentage)+1                #getting the percentage list based on the number of scenarios\n",
        "\n",
        "  #it was noticed that the A matrix followed a certain pattern when the scenarios increased. so it's been devided into 4 parts:\n",
        "  #the initial constraint part (x1+x2+x3+s1 = 500), The coefficient of land acres which will be multiplied with the percentage, other variables coefficients which stays the same and form a super diagonal matrix, the rest of the slacks coefficients which also form a super diagonal matrix\n",
        "  A_X_normal = np.array([[1, 1, 1, 1]])\n",
        "  A_X = np.array([[2.5, 0, 0, 0],\n",
        "                  [0, 3, 0, 0],\n",
        "                  [0, 0, -20, 0],\n",
        "                  [0, 0, 0, 0]])\n",
        "  A_Main_rest = np.array([[1, 0, -1, 0, 0, 0],\n",
        "                          [0, 1, 0, -1, 0, 0],\n",
        "                          [0, 0, 0, 0, 1, 1],\n",
        "                          [0, 0, 0, 0, 1, 0]])\n",
        "  A_Slacks_rest = np.array([[-1, 0, 0, 0],\n",
        "                            [0, -1, 0, 0],\n",
        "                            [0, 0, 1, 0],\n",
        "                            [0, 0, 0, 1]])\n",
        "  b_X = np.array([[500]])                                     #the initial constraint b (x1+x2+x3+s1 = 500), is not repeated\n",
        "  b_Rest = np.array([[200],[240],[0],[6000]])                 #rest of b, repeated as many scenarios\n",
        "  c_X = np.array([[150],[230],[260], [0]])                    #land acres c, are not repeated\n",
        "  c_Rest = np.array([[238],[210],[-170],[-150],[-36],[-10]])                        #other variables c, repeated as many scenarios\n",
        "  c_Slacks_rest = np.array([[0],[0],[0],[0]])                 #slacks c, repeated as many scenarios\n",
        "\n",
        "  A_Main_rest_new = np.kron(np.eye(number_of_scenarios), A_Main_rest)               #putting this part of the A matrix into the super diagonal matrix form\n",
        "  A_Main_rest_new[np.isclose(A_Main_rest_new, 0, atol=1e-10)] = 0                   #removing any small values generated instead of 0\n",
        "  A_Slacks_rest_new = np.kron(np.eye(number_of_scenarios), A_Slacks_rest)\n",
        "  A_Slacks_rest_new[np.isclose(A_Slacks_rest_new, 0, atol=9e-10)] = 0\n",
        "  A_X_new = np.vstack([A_X * perc for perc in percentage_list])                     #multiplying this part with our percentage set\n",
        "  A_Rest_new = np.hstack((A_X_new,A_Main_rest_new,A_Slacks_rest_new))               #stacking the three parts into on matrix\n",
        "  num_columns = A_Rest_new.shape[1]\n",
        "  zero_rows = np.zeros((1, num_columns - A_X_normal.shape[1]))\n",
        "  A = np.vstack([np.hstack([A_X_normal, zero_rows]), A_Rest_new])                   #adding the initial constraint coefficient and getting our full A matrix\n",
        "\n",
        "  b_Rest_new = np.vstack([b_Rest for num in range(number_of_scenarios)])            #multiplying the b part with as much constraint as we have then adding the constant part\n",
        "  b = np.vstack([b_X,b_Rest_new])\n",
        "\n",
        "  c_Rest_new = np.vstack([c_Rest * probabilities for num in range(number_of_scenarios)]) #multiplying the c part with as much constraint as we have then adding the constant part\n",
        "  c_Slacks_rest_new = np.vstack([c_Slacks_rest for num in range(number_of_scenarios)])\n",
        "  c = np.vstack((c_X,c_Rest_new,c_Slacks_rest_new))\n",
        "\n",
        "  A = np.round(A, decimals=8)                                                       #rounding the values to eliminate any problem with recurring or decimal values\n",
        "  A[np.isclose(A, 0, atol=1e-8)] = 0\n",
        "  c = np.round(c, decimals=8)\n",
        "  c[np.isclose(c, 0, atol=1e-8)] = 0\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  XB, IB, XN, IN = BIG_M(A,b,c)                                                     #calling our BIGM function which also solves the LP\n",
        "  total_index = np.hstack((IB,IN))                                                  #stacking the indices\n",
        "  total_X = np.vstack((XB,XN))                                                      #stacking the variables\n",
        "  total_index_flat = total_index.flatten()\n",
        "  sorting_index = np.argsort(total_index_flat)\n",
        "  X = total_X[sorting_index]                                                        #sorting the ivariables based on their indeces\n",
        "  Objective_value = c.T@X                                                           #getting the objective function value\n",
        "\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  Simplex_generated_data = Simplex_generated_data.append({'Scenarios_no': i_s, 'Objective_function_value': Objective_value.item(), 'Time_needed': elapsed_time, 'Largest_percentage_change': ((i_s-1)/2)*percentage}, ignore_index=True)"
      ],
      "metadata": {
        "id": "GMKV0eJE8oVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Simplex_generated_data.to_excel('output.xlsx', index=False, header=False) #the time to go through the scenarios kept increasing, so they've been done in batches, each batch stored in an excel file, to be latered combined and demonstrated"
      ],
      "metadata": {
        "id": "lCXBfxPpIBWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}